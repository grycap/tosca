tosca_definitions_version: tosca_simple_yaml_1_0

imports:
  - grycap_custom_types: https://raw.githubusercontent.com/grycap/tosca/main/custom_types.yaml

metadata:
  template_version: "1.0.0"
  template_name: Ollama + Open WebUI
  display_name: Install Ollama + Open WebUI

description: TOSCA template for deploying a Ollama + Open WebUI VM

topology_template:

  inputs:
    num_cpus:
      type: integer
      description: Number of virtual cpus for the VM
      default: 8
    mem_size:
      type: scalar-unit.size
      description: Amount of memory for the VM
      default: 64 GB
    disk_size:
      type: scalar-unit.size
      description: Size of the root disk of the VM (in case of 0, the disk will not be resized)
      default: 100 GB

    num_gpus:
      type: integer
      description: Number of GPUs to assing to this VM
      default: 0
    gpu_vendor:
      type: string
      description: GPU Vendor
      default: ''
      constraints:
        - valid_values: [ '', 'NVIDIA', 'AMD' ]
    gpu_model:
      type: string
      description: GPU Model
      default: ''

    ollama_nvidia_support:
      type: boolean
      description: Flag to add the NVIDIA runtime to the Ollama installation
      default: false
      constraints:
        - valid_values: [ false, true ]

    ollama_driver_version:
      type: string
      description: NVIDIA Driver version to install
      default: "510"

    ollama_models_name:
      type: list
      entry_schema:
        type: string
      description: Name of the AI models to install (see https://ollama.com/models)
      default: ["llama2", "deepseek-r1:q4_0"]
      required: yes

  node_templates:

    ollama:
      type: tosca.nodes.ec3.Application
      requirements:
        - host: simple_node
      artifacts:
        docker_role:
          file: grycap.docker
          type: tosca.artifacts.AnsibleGalaxy.role
      capabilities:
        endpoint:
          properties:
            ports:
              https:
                protocol: tcp
                source: 443
      interfaces:
        Standard:
          configure:
            implementation: https://raw.githubusercontent.com/grycap/tosca/main/artifacts/ollama.yml
            inputs:
              ollama_nvidia_support: { get_input: ollama_nvidia_support }
              ollama_driver_version: { get_input: ollama_driver_version }
              ollama_models_name: { get_input: ollama_models_name }
              node_public_address: { get_attribute: [ simple_node, public_address, 0 ] }
              dns_node_name: ""

    simple_node:
      type: tosca.nodes.indigo.Compute
      capabilities:
        endpoint:
          properties:
            network_name: PUBLIC
        host:
          properties:
            disk_size: { get_input: disk_size }
            num_cpus: { get_input: num_cpus }
            mem_size: { get_input: mem_size }
            num_gpus: { get_input: num_gpus }
            gpu_vendor: { get_input: gpu_vendor }
            gpu_model: { get_input: gpu_model }
        os:
          properties:
            type: linux
            distribution: ubuntu

  outputs:
    openwebui_url:
      value: { concat: [ "http://", { get_attribute: [ simple_node, public_address, 0 ] }, "/"] }
